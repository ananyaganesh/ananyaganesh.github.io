<!DOCTYPE html>
<html lang="en">
<head>
    <meta name=viewport content=“width=800”>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        a {
            color: #1772d0;
            text-decoration: none;
        }

        a:focus, a:hover {
            color: #f09228;
            text-decoration: none;
        }

        body, td, th, tr, p, a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 20px;
        }

        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
            font-weight: 700
        }

        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }

        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }

        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        span.highlight {
            background-color: #ffffd0;
        }
    </style>
    <link rel="icon" type="image/png" href="umass.jpg">
    <title>Projects</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
          type='text/css'>
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
</head>
<body>
<table width="100%" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="lisa.PNG" height="200" width="200">
                        </p>
                    </td>
                    <td width="40%" valign="middle">
                        <p>
                            <a name="LISA-SRL">
                                <heading>Improved representations for semantic role labeling using fine-grained roles
                                </heading>
                            </a>
                        </p>
                        <p align="left">
                            Semantic role labeling (SRL) is a shallow semantic parsing task that helps determine
                            <i>who</i> did <i>what</i> to <i>whom</i> at <i>where</i> by recovering the latent
                            predicate-argument structure of the sentence. SRL is a fundamental problem in NLP that is
                            also useful in applications such as question answering, machine translation and information
                            extraction. I've been working on reducing labeling errors on a state-of-the art SRL model
                            called Linguistically-Informed Self Attention (<a href="https://arxiv.org/abs/1804.08199">LISA</a>)
                            developed by <a href="http://people.cs.umass.edu/~strubell">Emma Strubell</a>. LISA is a
                            neural network model that performs multi-task learning across dependency parsing,
                            part-of-speech tagging, predicate detection and SRL.
                        </p>
                        <p align="left">

                            Error analysis on the model revealed that if labeling errors alone were fixed, the score
                            would improve by 5.8 absolute F1. That is, the predicates and arguments were identified
                            correctly in several cases, but classified wrong. My analysis further showed that 31% of the
                            labeling errors were due to core argument confusion in the PropBank label set (verb-specific
                            roles from ARG0-ARG5). While PropBank is a useful semantic formalism, it defines
                            coarse-grained labels which aren't strictly associated with a role. Since the meaning of a
                            role changes across different predicates, it can be difficult for the model to learn these
                            roles. To fix this, we're augmenting PropBank labels with finer-grained VerbNet labels by
                            first predicting VerbNet roles and using the predictions to compose an auxiliary role
                            representation which is then utilized for PropBank SRL.
                        </p>

                    </td>
                    <td width="40%" valign="middle">
                        Jun 2018 - Present
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="wsi.jpg" height="200" width="200">
                        </p>
                    </td>
                    <td width="50%" valign="middle">
                        <p>
                            <heading>Graph-Based Word Sense Induction</heading>
                        </p>
                        <p align="justify">
                            As part of an independent study, I worked with Lexalytics in Spring 2018 with the objective
                            of improving sentiment analysis by resolving polysemy. Polysemy is the phenomenon of a
                            single word having multiple senses, like <i>bank</i> the financial institution and
                            <i>bank</i> as in river bank, and the task of selecting the right sense is called word sense
                            disambiguation. We developed an efficient method to perform word sense
                            induction using graph-based clustering.
                        </p>
                        <p>
                            The key idea here is to build an ego network of
                        </p>
                    </td>
                    <td width="30%">
                        Feb 2018 - Apr 2018
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="dil.PNG" height="200" width="200">
                        </p>
                    </td>
                    <td width="50%" valign="middle">
                        <p>
                            <heading>Faster dependency parsing using iterative dilated convolutions</heading>
                        </p>
                        <p>
                            Iterative dilated CNNs are a stack of dilated convolutional layers, found to be effective
                            for
                            fast sequence labeling. I worked on integrating ID-CNNs into the LISA model
                            as a replacement for the LSTM.
                        </p>
                    </td>
                    <td width="30%">
                        Mar 2018 - Present?
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="low-shot.PNG" height="200" width="200">
                        </p>
                    </td>
                    <td width="50%" valign="middle">
                        <p>
                            <heading>Low-shot visual recognition for faces</heading>
                        </p>
                        <p>
                            As a course project for Neural Networks, I re-implemented Hariharan and Girshick's approach
                            for low-shot visual recognition using hallucination and shrinking features.
                        </p>
                    </td>
                    <td width="30%">
                        Mar 2018 - Apr 2018
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="geo.PNG" height="200" width="200">
                        </p>
                    </td>
                    <td width="50%">
                        <p>
                            <heading>Visual Place Recognition</heading>
                        </p>
                        <p>
                            As a course project for Computer Vision, I worked on automatically identifying the location
                            of a
                            place given only an image and no other metadata.
                        </p>
                    </td>
                    <td width="30%">
                        Oct 2017 - Dec 2017
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="siren.jpg">
                        </p>
                    </td>
                    <td width="50%" valign="middle">
                        <p>
                            <heading>The Sound of Sirens</heading>
                        </p>
                        <p>
                            This was a project that I worked on over 36 hours at HackUMass 2017 along with some cool
                            undergrads that I met at the venue. We built a signaling system that could alert hearing
                            impaired drivers if a vehicle with sirens is in the vicinity.
                        </p>
                    </td>
                    <td width="30%">
                        Nov 2017 - Nov 2017
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="quoterequest.png">
                        </p>
                    </td>
                    <td width="50%" valign="middle">
                        <p>
                            <heading>CEGAR-based tool for specifying system properties</heading>
                        </p>
                        <p>
                            This was my bachelor's thesis in the field of model checking.
                        </p>
                    </td>
                    <td width="30%">
                        Jan 2017 - May 2017
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="siren.jpg">
                        </p>
                    </td>
                    <td width="70%" valign="middle">
                        <p>
                            <heading>Detecting variability in multi-word expressions</heading>
                        </p>
                        <p>
                            I worked as a research intern at the Computational Linguistics lab at Nara Institute of
                            Science
                            and Technology in Japan.
                        </p>
                    </td>
                    <td width="30%">
                        Jun 2016 - Jul 2016
                    </td>
                </tr>
                <tr>
                    <td width="20%" valign="middle">
                        <p>
                            <img src="bull.jpg">
                        </p>
                    </td>
                    <td width="70%" valign="middle">
                        <p>
                            <heading>Sentiment analysis for foreign exchange trading</heading>
                        </p>
                        <p>
                            As a data science intern at Serendio Inc., I worked on developing a machine learning model
                            to
                            gauge expert opinion on trends in currency exchange using sentiment analysis.
                        </p>
                    </td>
                    <td width="30%">
                        Jan 2016 - Feb 2016
                    </td>
                </tr>

            </table>


            <script type="text/javascript">
                var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
                document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

            </script>
            <script type="text/javascript">
                try {
                    var pageTracker = _gat._getTracker("UA-7580334-1");
                    pageTracker._trackPageview();
                } catch (err) {
                }
            </script>
        </td>
    </tr>
</table>
</body>
</html>